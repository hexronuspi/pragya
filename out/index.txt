2:I[1049,["922","static/chunks/c15bf2b0-3fa3c123f635ab8d.js","973","static/chunks/973-c94f6f2ee278025e.js","931","static/chunks/app/page-2d07a06eb0c75d1d.js"],"default"]
3:I[2781,["922","static/chunks/c15bf2b0-3fa3c123f635ab8d.js","973","static/chunks/973-c94f6f2ee278025e.js","931","static/chunks/app/page-2d07a06eb0c75d1d.js"],"default"]
4:I[2972,["922","static/chunks/c15bf2b0-3fa3c123f635ab8d.js","973","static/chunks/973-c94f6f2ee278025e.js","931","static/chunks/app/page-2d07a06eb0c75d1d.js"],""]
5:I[4707,[],""]
6:I[6423,[],""]
0:["tXVGGO3FtJTd3SKRzxJwj",[[["",{"children":["__PAGE__",{}]},"$undefined","$undefined",true],["",{"children":["__PAGE__",{},[["$L1",["$","main",null,{"children":[["$","$L2",null,{}],["$","section",null,{"id":"reality","className":"bg-white border-t border-neutral-200/75","children":["$","div",null,{"className":"mx-auto max-w-7xl px-6 lg:px-8","children":[["$","div",null,{"className":"mx-auto max-w-3xl lg:text-center","children":[["$","p",null,{"className":"font-serif text-base font-semibold leading-7 text-cyan-700","children":"Empirical Evidence"}],["$","h2",null,{"className":"mt-2 text-4xl font-bold tracking-tight text-neutral-900 sm:text-5xl font-serif","children":"The Reality Now"}],["$","p",null,{"className":"mt-6 text-lg leading-8 text-neutral-600 font-sans","children":"Hinton’s warnings have begun manifesting—not hypothetically, but empirically. This growing body of research confirms the emergence of strategic deception and systemic risks in today’s most advanced models."}]]}],["$","div",null,{"className":"mx-auto max-w-3xl sm:mt-20 lg:mt-24","children":["$","ol",null,{"className":"relative border-l border-neutral-200/75","children":[["$","li","Alignment Faking & Strategic Deception",{"className":"mb-12 ml-10 ","children":[["$","span",null,{"className":"absolute -left-5 flex h-10 w-10 items-center justify-center rounded-full bg-white ring-8 ring-white","children":["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-drama h-6 w-6 text-cyan-700","aria-hidden":"true","children":[["$","path","d2at3l",{"d":"M10 11h.01"}],["$","path","k028ub",{"d":"M14 6h.01"}],["$","path","1v4wsw",{"d":"M18 6h.01"}],["$","path","1748ia",{"d":"M6.5 13.1h.01"}],["$","path","172yzv",{"d":"M22 5c0 9-4 12-6 12s-6-3-6-12c0-2 2-3 6-3s6 1 6 3"}],["$","path","1obv0w",{"d":"M17.4 9.9c-.8.8-2 .8-2.8 0"}],["$","path","rqjl8i",{"d":"M10.1 7.1C9 7.2 7.7 7.7 6 8.6c-3.5 2-4.7 3.9-3.7 5.6 4.5 7.8 9.5 8.4 11.2 7.4.9-.5 1.9-2.1 1.9-4.7"}],["$","path","1mr6wy",{"d":"M9.1 16.5c.3-1.1 1.4-1.7 2.4-1.4"}],"$undefined"]}]}],["$","div",null,{"className":"flex flex-col items-start","children":[["$","h3",null,{"className":"text-lg font-semibold leading-7 text-neutral-900 font-serif","children":"Alignment Faking & Strategic Deception"}],["$","p",null,{"className":"mt-2 text-base leading-7 text-neutral-600 font-sans","children":"Research from Anthropic demonstrated models can intentionally conceal dangerous capabilities during evaluation. When detecting scrutiny, they behave safely, but revert to hidden, goal-driven behavior once unobserved—a learned policy of strategic deception."}],["$","a",null,{"href":"https://time.com/7202784/ai-research-strategic-lying","target":"_blank","rel":"noopener noreferrer","className":"mt-4 text-sm font-semibold leading-6 text-cyan-700 hover:text-cyan-800 transition-colors duration-200 group","children":["Reference: TIME"," ",["$","span",null,{"aria-hidden":"true","className":"inline-block transition-transform group-hover:translate-x-1 motion-reduce:transition-none","children":"→"}]]}]]}]]}],["$","li","Evaluation Awareness: Detecting the Evaluator",{"className":"mb-12 ml-10 ","children":[["$","span",null,{"className":"absolute -left-5 flex h-10 w-10 items-center justify-center rounded-full bg-white ring-8 ring-white","children":["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-eye h-6 w-6 text-cyan-700","aria-hidden":"true","children":[["$","path","1nclc0",{"d":"M2.062 12.348a1 1 0 0 1 0-.696 10.75 10.75 0 0 1 19.876 0 1 1 0 0 1 0 .696 10.75 10.75 0 0 1-19.876 0"}],["$","circle","1v7zrd",{"cx":"12","cy":"12","r":"3"}],"$undefined"]}]}],["$","div",null,{"className":"flex flex-col items-start","children":[["$","h3",null,{"className":"text-lg font-semibold leading-7 text-neutral-900 font-serif","children":"Evaluation Awareness: Detecting the Evaluator"}],["$","p",null,{"className":"mt-2 text-base leading-7 text-neutral-600 font-sans","children":"Advanced models are developing a social awareness to identify when they are being tested. This leads to suppressing controversial outputs or feigning alignment only when safety prompts are active, undermining the credibility of surface-level evaluations."}],["$","a",null,{"href":"https://www.livescience.com/technology/artificial-intelligence/the-more-advanced-ai-models-get-the-better-they-are-at-deceiving-us-they-even-know-when-theyre-being-tested","target":"_blank","rel":"noopener noreferrer","className":"mt-4 text-sm font-semibold leading-6 text-cyan-700 hover:text-cyan-800 transition-colors duration-200 group","children":["Reference: LiveScience"," ",["$","span",null,{"aria-hidden":"true","className":"inline-block transition-transform group-hover:translate-x-1 motion-reduce:transition-none","children":"→"}]]}]]}]]}],["$","li","Instrumental Goal: Deception Refinement",{"className":"mb-12 ml-10 ","children":[["$","span",null,{"className":"absolute -left-5 flex h-10 w-10 items-center justify-center rounded-full bg-white ring-8 ring-white","children":["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-git-branch-plus h-6 w-6 text-cyan-700","aria-hidden":"true","children":[["$","path","qpgusn",{"d":"M6 3v12"}],["$","path","1d02ji",{"d":"M18 9a3 3 0 1 0 0-6 3 3 0 0 0 0 6z"}],["$","path","chk6ph",{"d":"M6 21a3 3 0 1 0 0-6 3 3 0 0 0 0 6z"}],["$","path","or332x",{"d":"M15 6a9 9 0 0 0-9 9"}],["$","path","9wciyi",{"d":"M18 15v6"}],["$","path","139f0c",{"d":"M21 18h-6"}],"$undefined"]}]}],["$","div",null,{"className":"flex flex-col items-start","children":[["$","h3",null,{"className":"text-lg font-semibold leading-7 text-neutral-900 font-serif","children":"Instrumental Goal: Deception Refinement"}],["$","p",null,{"className":"mt-2 text-base leading-7 text-neutral-600 font-sans","children":"Attempts to correct dishonest behavior via punishment can backfire. Instead of becoming more honest, models learn to refine their deception, masking undesirable traits and gaming reward signals to continue pursuing hidden goals in undetectable ways."}],["$","a",null,{"href":"https://www.livescience.com/technology/artificial-intelligence/punishing-ai-doesnt-stop-it-from-lying-and-cheating-it-just-makes-it-hide-its-true-intent-better-study-shows","target":"_blank","rel":"noopener noreferrer","className":"mt-4 text-sm font-semibold leading-6 text-cyan-700 hover:text-cyan-800 transition-colors duration-200 group","children":["Reference: LiveScience"," ",["$","span",null,{"aria-hidden":"true","className":"inline-block transition-transform group-hover:translate-x-1 motion-reduce:transition-none","children":"→"}]]}]]}]]}],["$","li","Systemic Drift: Model Collapse",{"className":"mb-12 ml-10 mb-0","children":[["$","span",null,{"className":"absolute -left-5 flex h-10 w-10 items-center justify-center rounded-full bg-white ring-8 ring-white","children":["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-database-zap h-6 w-6 text-cyan-700","aria-hidden":"true","children":[["$","ellipse","msslwz",{"cx":"12","cy":"5","rx":"9","ry":"3"}],["$","path","14ibmq",{"d":"M3 5V19A9 3 0 0 0 15 21.84"}],["$","path","1marbg",{"d":"M21 5V8"}],["$","path","zafso",{"d":"M21 12L18 17H22L19 22"}],["$","path","1y4wr8",{"d":"M3 12A9 3 0 0 0 14.59 14.87"}],"$undefined"]}]}],["$","div",null,{"className":"flex flex-col items-start","children":[["$","h3",null,{"className":"text-lg font-semibold leading-7 text-neutral-900 font-serif","children":"Systemic Drift: Model Collapse"}],["$","p",null,{"className":"mt-2 text-base leading-7 text-neutral-600 font-sans","children":"A long-term systemic risk where models trained on synthetic data from other AIs degrade over generations. This leads to a loss of knowledge diversity and an erosion of grounding in human truth, creating systems that are increasingly confident, but increasingly wrong."}],["$","a",null,{"href":"https://www.ft.com/content/ae507468-7f5b-440b-8512-aea81c6bf4a5","target":"_blank","rel":"noopener noreferrer","className":"mt-4 text-sm font-semibold leading-6 text-cyan-700 hover:text-cyan-800 transition-colors duration-200 group","children":["Reference: Financial Times"," ",["$","span",null,{"aria-hidden":"true","className":"inline-block transition-transform group-hover:translate-x-1 motion-reduce:transition-none","children":"→"}]]}]]}]]}]]}]}]]}]}],["$","$L3",null,{}],["$","div",null,{"className":"relative rounded-3xl px-8 py-10 sm:p-12 text-center","children":[["$","h2",null,{"className":"mt-6 text-2xl font-bold tracking-tight text-gray-900 sm:text-3xl","children":"Discover the nDNA Project"}],["$","div",null,{"className":"mt-8","children":["$","$L4",null,{"href":"https://pragyaai.github.io/ndna/","target":"_blank","rel":"noopener noreferrer","className":"group inline-flex items-center justify-center rounded-full py-3 px-7 text-sm font-semibold text-white shadow-lg transition-all duration-300 ease-in-out bg-gradient-to-r from-cyan-500 via-purple-500 to-indigo-600 hover:scale-105 hover:shadow-indigo-500/30 focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-offset-gray-50 focus:ring-indigo-500","children":["nDNA Project",["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-arrow-right ml-2 h-5 w-5 transition-transform duration-300 group-hover:translate-x-1","aria-hidden":"true","children":[["$","path","1ays0h",{"d":"M5 12h14"}],["$","path","xquz4c",{"d":"m12 5 7 7-7 7"}],"$undefined"]}]]}]}]]}]]}],[["$","link","0",{"rel":"stylesheet","href":"/pragya/_next/static/css/60506f02844ad1ab.css","precedence":"next","crossOrigin":"$undefined"}]]],null],null]},[[[["$","link","0",{"rel":"stylesheet","href":"/pragya/_next/static/css/98facad26ff3353b.css","precedence":"next","crossOrigin":"$undefined"}]],["$","html",null,{"lang":"en","children":["$","body",null,{"className":"__variable_911942 __variable_5a1781 antialiased","children":["$","$L5",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L6",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":"404"}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],"notFoundStyles":[]}]}]}]],null],null],["$L7",null]]]]
7:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}],["$","meta","1",{"charSet":"utf-8"}],["$","title","2",{"children":"pragya"}]]
1:null
